---
title: "LiveNet: A Robust, Minimally Invasive Multi-Robot Control for Safe and Live Navigation in Constrained Environments"
collection: publications
category: conferences
status: submitted
permalink: /publication/livenet
excerpt: ''
date: 2025-06-04
venue: '7th Annual Learning for Dynamics and Controls Conference'
venueurl: 'https://sites.google.com/umich.edu/l4dc2025/'
paperurl: '../files/livenet.pdf'
# citation: 'Your Name, You. (2024). &quot;Paper Title Number 3.&quot; <i>GitHub Journal of Bugs</i>. 1(3).'
---

### Abstract

Robots in densely populated real-world environments frequently encounter constrained and cluttered situations such as passing through narrow doorways, hallways, and corridor intersections, where conflicts over limited space result in collisions or deadlocks among the robots. Current decentralized state-of-the-art optimization- and neural network-based approaches (i) are predominantly designed for general open spaces, and (ii) are overly conservative, either guaranteeing safety, or liveness, but not both. While some solutions rely on centralized conflict resolution, their highly invasive trajectories make them impractical for real-world deployment. This paper introduces LiveNet, a fully decentralized and robust neural network controller that enables human-like yielding and passing, resulting in agile, non-conservative, deadlock-free, and safe, navigation in congested, conflict-prone spaces. LiveNet is minimally invasive, without requiring inter-agent communication or cooperative behavior. The key insight behind LiveNet is a unified CBF formulation for *simultaneous* safety and liveness, which we integrate within a neural network for robustness. We evaluated LiveNet in simulation and found that general multi-robot optimization- and learning-based navigation methods fail to even reach the goal, and while methods designed specially for such environments do succeed, they are 10--20x slower, 4--5x more invasive, and much less robust to variations in the scenario configuration such as changes in the start states and goal states, among others. We open-source the LiveNet code at [**https://github.com/srikarg89/LiveNet**](https://github.com/srikarg89/LiveNet).

[Read more](https://arxiv.org/abs/2412.04659)